version: '3'
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - 9090:9090
    mem_limit: 300m
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    depends_on:
      - cadvisor
    restart: always
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    container_name: cadvisor
    restart: always
    privileged: true
    mem_limit: 150m
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
      - /var/run/docker.sock:/var/run/docker.sock      

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - 3000:3000
    mem_limit: 300m
    restart: always
    volumes:
      - grafana-storage:/var/lib/grafana
      # - ./monitoring-configs/grafana.ini:/etc/grafana/grafana.ini
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
      - cadvisor
    # command:
    #   - --config=/etc/grafana/grafana.ini
  server:
    container_name: server
    shm_size: '6g'
    build:
      context: .
      dockerfile: Dockerfile
    # mem_limit: 1g
    command: python server.py
    restart: always
    environment:
      CLIENTS: "client1:6001,client2:6002"
      FLASK_RUN_PORT: 6000
      DOCKER_HOST_IP: host.docker.internal
      MLFLOW_TRACKING_URI: http://mlflow_server:5010
    volumes:
      - .:/app
      - /var/run/docker.sock:/var/run/docker.sock      
    ports:
      - "6000:6000"
      - "8265:8265"
    depends_on:
      - mlflow_server
      - prometheus
      - grafana
  mlflow_server:
    container_name: mlflow_server
    restart: always
    build:
      context: .
      dockerfile: Dockerfile
    mem_limit: 500m
    command: mlflow server --host 0.0.0.0 --port 5010 --default-artifact-root /mlflow/artifacts --backend-store-uri /mlflow/runs
    volumes:
      - ./mlflow:/mlflow
      - ./mlruns:/mlruns 
    ports:
      - "5010:5010"
  
  client1:
    container_name: client1
    restart: always
    build:
      context: .
      dockerfile: Dockerfile
    mem_limit: 4g
    command: python client.py --server_address=server:8080
    volumes:
      - .:/app
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "6001:6001"
    depends_on:
      - server
    environment:
      FLASK_RUN_PORT: 6001
      container_name: client1
      DOCKER_HOST_IP: host.docker.internal
      MLFLOW_TRACKING_URI: http://mlflow_server:5010
  client2:
    container_name: client2
    restart: always
    build:
      context: .
      dockerfile: Dockerfile
    command: python client.py --server_address=server:8080
    depends_on:
      - server
    mem_limit: 4g
    volumes:
      - .:/app
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "6002:6002"
    environment:
      FLASK_RUN_PORT: 6002
      container_name: client2
      DOCKER_HOST_IP: host.docker.internal
      MLFLOW_TRACKING_URI: http://mlflow_server:5010
    # deploy:
    #     resources:
    #       limits:
    #         memory: 6g
    # mem_reservation: 2g
  # client3:
  #   container_name: client3
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   # mem_limit: 1g
  #   command: python client.py --server_address=server:8080
  #   depends_on:
  #     - server
  #   volumes:
  #     - .:/app
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   ports:
  #     - "6003:6003"
  #   environment:
  #     FLASK_RUN_PORT: 6003
  #     container_name: client3
  #     DOCKER_HOST_IP: host.docker.internal
  #     MLFLOW_TRACKING_URI: http://mlflow_server:5010
  #   # deploy:
  #   #     resources:
  #   #       limits:
  #   #         memory: 6g
  #   # mem_reservation: 2g
  # client4:
  #   container_name: client4
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   # mem_limit: 1g
  #   command: python client.py --server_address=server:8080
  #   depends_on:
  #     - server
  #   volumes:
  #     - .:/app
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   ports:
  #     - "6004:6004"
  #   environment:
  #     FLASK_RUN_PORT: 6004
  #     container_name: client4
  #     DOCKER_HOST_IP: host.docker.internal
  #     MLFLOW_TRACKING_URI: http://mlflow_server:5010
  #   # deploy:
  #   #     resources:
  #   #       limits:
  #   #         memory: 6g
  #   # mem_reservation: 2g
  # client5:
  #     container_name: client5
  #     build:
  #       context: .
  #       dockerfile: Dockerfile
  #     command: python client.py --server_address=server:8080
  #     depends_on:
  #     - server
  #     volumes:
  #       - .:/app
  #       - /var/run/docker.sock:/var/run/docker.sock
  #     ports:
  #       - "6005:6005"
  #     environment:
  #       FLASK_RUN_PORT: 6005
  #       container_name: client5
  #       DOCKER_HOST_IP: host.docker.internal
  #       MLFLOW_TRACKING_URI: http://mlflow_server:5010
  #     # deploy:
  #     #   resources:
  #     #     limits:
  #     #       memory: 6g
  #     # mem_reservation: 2g
volumes:
  grafana-storage:
 
  
